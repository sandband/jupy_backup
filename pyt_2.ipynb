{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tables\n",
    "import uuid\n",
    "import random\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Constants##\n",
    "RAND_UPPER_LIMIT = 3\n",
    "HDF5_FILE_NAME = 'hdf_base.h5'\n",
    "FILE_LOG_GROUP_NAME = 'group_fl'\n",
    "FILE_LOG_TABLE_NAME = 'file_digest'\n",
    "\n",
    "class file_log_schema(tables.IsDescription):\n",
    "    file_name = tables.StringCol(126)\n",
    "    parent_name = tables.StringCol(48)\n",
    "    digest_time = tables.Time64Col()    \n",
    "\n",
    "def random_file_generator(extension : str) -> str:\n",
    "    return str(uuid.uuid4()) + '.' + str(extension)\n",
    "\n",
    "def create_file(folder_location : str, file_name : str):\n",
    "    new_file_path = os.path.join(folder_location, file_name)\n",
    "    with open(new_file_path, 'a') as f:\n",
    "        f.close()\n",
    "        \n",
    "def add_file():\n",
    "    folder_loc = os.getcwd()\n",
    "    file_name = random_file_generator(extension = 'txt')\n",
    "    print(file_name)\n",
    "    create_file(folder_loc, file_name)\n",
    "\n",
    "#############\n",
    "#Step 2\n",
    "####\n",
    "def randomly_add_files():\n",
    "    rand_int = random.randint(1, RAND_UPPER_LIMIT)\n",
    "    print(rand_int)\n",
    "    ind = 1\n",
    "    while ind<=rand_int:\n",
    "        add_file()\n",
    "        ind = ind +1\n",
    "        \n",
    "###############\n",
    "#Step 3\n",
    "###\n",
    "def create_hdf5_if_not():\n",
    "    if(not([x for x in os.listdir() if HDF5_FILE_NAME in x])):\n",
    "        print('creating one!!')\n",
    "        create_hdf_nodes()\n",
    "    else:\n",
    "        print('exists!!')\n",
    "\n",
    "def create_hdf_nodes():\n",
    "    with tables.open_file(HDF5_FILE_NAME, mode='w') as f:\n",
    "        root = f.root\n",
    "        group = f.create_group(root, FILE_LOG_GROUP_NAME)\n",
    "        print(group)\n",
    "        file_log_table = f.create_table(group,FILE_LOG_TABLE_NAME,file_log_schema,'file logger')\n",
    "        print(f)\n",
    "        print(str(f))\n",
    "        print(repr(f))\n",
    "        f.close()\n",
    "\n",
    "def add_file_logger_rec(file_name, parent_name):\n",
    "    with tables.open_file(HDF5_FILE_NAME, mode='w') as f:\n",
    "        print('inside add_file_logger_rec')\n",
    "        print(f)\n",
    "        print(str(f))\n",
    "        print(repr(f))\n",
    "        fl_tab = f.root.group_fl.file_digest\n",
    "        rec = fl_tab.row\n",
    "        rec['file_name'] = file_name\n",
    "        rec['parent_name'] = parent_name\n",
    "        rec['digest_time'] = datetime.datetime.now()\n",
    "        rec.append()\n",
    "        fl_tab.flush()\n",
    "        print(f)\n",
    "        print(str(f))\n",
    "        print(repr(f))\n",
    "        f.close()\n",
    "\n",
    "def yet_to_be_digested() -> list:\n",
    "    txt_file_list = [x for x in os.listdir() if '.txt' in x]\n",
    "    with tables.open_file(HDF5_FILE_NAME, mode='r') as f:\n",
    "        fl_tab = f.root.group_fl.file_digest #f.get_node(f.get_node(f.root,FILE_LOG_GROUP_NAME), FILE_LOG_TABLE_NAME)        \n",
    "        print(type(fl_tab))\n",
    "        print(dir(fl_tab))\n",
    "        for r in fl_tab.iterrows():\n",
    "            if(r['file_name'] in txt_file_list):\n",
    "                txt_file_list.remove(r['file_name'])\n",
    "        f.close()\n",
    "    with tables.open_file(HDF5_FILE_NAME, mode='r') as f2:\n",
    "        print(f2)\n",
    "        print(str(f2))\n",
    "        print(repr(f2))\n",
    "    return txt_file_list\n",
    "    \n",
    "        \n",
    "def digest_files():\n",
    "    randomly_add_files()    \n",
    "    create_hdf5_if_not()\n",
    "    ytbd = [x for x in os.listdir() if '.txt' in x]#yet_to_be_digested()\n",
    "    for f in ytbd:\n",
    "        print(f)\n",
    "        add_file_logger_rec(f, 'const')\n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "14d61665-f34a-40d5-aa41-686a834d7889.txt\n",
      "4aa46781-d572-4a6e-bbd7-5a25e81ea716.txt\n",
      "1\n",
      "35d0eb08-b2f3-4ea3-b76d-7bd35e8117a7.txt\n",
      "creating one!!\n",
      "/group_fl (Group) ''\n",
      "hdf_base.h5 (File) ''\n",
      "Last modif.: 'Mon Aug 13 09:55:18 2018'\n",
      "Object Tree: \n",
      "/ (RootGroup) ''\n",
      "/group_fl (Group) ''\n",
      "/group_fl/file_digest (Table(0,)) 'file logger'\n",
      "\n",
      "hdf_base.h5 (File) ''\n",
      "Last modif.: 'Mon Aug 13 09:55:18 2018'\n",
      "Object Tree: \n",
      "/ (RootGroup) ''\n",
      "/group_fl (Group) ''\n",
      "/group_fl/file_digest (Table(0,)) 'file logger'\n",
      "\n",
      "File(filename=hdf_base.h5, title='', mode='w', root_uep='/', filters=Filters(complevel=0, shuffle=False, bitshuffle=False, fletcher32=False, least_significant_digit=None))\n",
      "/ (RootGroup) ''\n",
      "/group_fl (Group) ''\n",
      "/group_fl/file_digest (Table(0,)) 'file logger'\n",
      "  description := {\n",
      "  \"digest_time\": Time64Col(shape=(), dflt=0.0, pos=0),\n",
      "  \"file_name\": StringCol(itemsize=126, shape=(), dflt=b'', pos=1),\n",
      "  \"parent_name\": StringCol(itemsize=48, shape=(), dflt=b'', pos=2)}\n",
      "  byteorder := 'little'\n",
      "  chunkshape := (360,)\n",
      "\n",
      "35d0eb08-b2f3-4ea3-b76d-7bd35e8117a7.txt\n",
      "inside add_file_logger_rec\n",
      "hdf_base.h5 (File) ''\n",
      "Last modif.: 'Mon Aug 13 09:55:18 2018'\n",
      "Object Tree: \n",
      "/ (RootGroup) ''\n",
      "\n",
      "hdf_base.h5 (File) ''\n",
      "Last modif.: 'Mon Aug 13 09:55:18 2018'\n",
      "Object Tree: \n",
      "/ (RootGroup) ''\n",
      "\n",
      "File(filename=hdf_base.h5, title='', mode='w', root_uep='/', filters=Filters(complevel=0, shuffle=False, bitshuffle=False, fletcher32=False, least_significant_digit=None))\n",
      "/ (RootGroup) ''\n",
      "\n"
     ]
    },
    {
     "ename": "NoSuchNodeError",
     "evalue": "group ``/`` does not have a child named ``group_fl``",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNoSuchNodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-719c67a69faa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mrandomly_add_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#create_hdf5_if_not()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdigest_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m#with tables.open_file(HDF5_FILE_NAME, mode='r') as f:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#    print(str(f))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-220721d817f0>\u001b[0m in \u001b[0;36mdigest_files\u001b[0;34m()\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mytbd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0madd_file_logger_rec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'const'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-220721d817f0>\u001b[0m in \u001b[0;36madd_file_logger_rec\u001b[0;34m(file_name, parent_name)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mfl_tab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup_fl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_digest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0mrec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfl_tab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mrec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'file_name'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tables/group.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    838\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_g_add_children_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 840\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_f_get_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tables/group.py\u001b[0m in \u001b[0;36m_f_get_child\u001b[0;34m(self, childname)\u001b[0m\n\u001b[1;32m    710\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_g_check_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 712\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_g_check_has_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchildname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0mchildpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoin_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_v_pathname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchildname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tables/group.py\u001b[0m in \u001b[0;36m_g_check_has_child\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    397\u001b[0m             raise NoSuchNodeError(\n\u001b[1;32m    398\u001b[0m                 \u001b[0;34m\"group ``%s`` does not have a child named ``%s``\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m                 % (self._v_pathname, name))\n\u001b[0m\u001b[1;32m    400\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnode_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNoSuchNodeError\u001b[0m: group ``/`` does not have a child named ``group_fl``"
     ]
    }
   ],
   "source": [
    "#add_file()\n",
    "randomly_add_files()\n",
    "#create_hdf5_if_not()\n",
    "digest_files()\n",
    "#with tables.open_file(HDF5_FILE_NAME, mode='r') as f:\n",
    "#    print(str(f))\n",
    "#add_file_logger_rec('test','test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
